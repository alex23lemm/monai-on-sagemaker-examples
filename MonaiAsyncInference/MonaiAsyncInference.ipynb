{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8712c732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu-west-1\n",
      "arn:aws:iam::617011600974:role/service-role/AmazonSageMaker-ExecutionRole-20210316T155032\n",
      "sagemaker-eu-west-1-617011600974\n",
      "monai-async-inference-brain-tumor\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import torch\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "import boto3\n",
    "import datetime\n",
    "import time\n",
    "from time import strftime,gmtime\n",
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import sys\n",
    "import io\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "sm_session = sagemaker.session.Session()\n",
    "sm_client = boto_session.client(\"sagemaker\")\n",
    "sm_runtime = boto_session.client(\"sagemaker-runtime\")\n",
    "sns_client = boto3.client('sns')\n",
    "region = boto_session.region_name\n",
    "bucket = sm_session.default_bucket()\n",
    "prefix = 'monai-async-inference-brain-tumor'\n",
    "role = \"arn:aws:iam::617011600974:role/service-role/AmazonSageMaker-ExecutionRole-20210316T155032\"\n",
    "\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)\n",
    "print(prefix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "62d55c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘model_and_code’: File exists\n",
      "mkdir: cannot create directory ‘model_and_code/code’: File exists\n",
      "cp: omitting directory ‘./source/__pycache__’\n",
      "./\n",
      "./model.pth\n",
      "./code/\n",
      "./code/inference.py\n",
      "./code/requirements.txt\n",
      "./code/__init__.py\n",
      "s3://sagemaker-eu-west-1-617011600974/monai-async-inference-brain-tumor/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"MONAI-DEMO-MultiModelModel\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "#model_url = \"s3://sagemaker-eu-west-1-617011600974/monai-on-sagemaker-docker-2022-06-03-08-24-03-985/output/model.tar.gz\"\n",
    "\n",
    "!mkdir model_and_code\n",
    "!cp ./model/model.pth model_and_code/\n",
    "#torch.save(model, 'model_and_code/model.pth')\n",
    "!mkdir model_and_code/code\n",
    "!cp ./source/* model_and_code/code\n",
    "!tar cvzf model.tar.gz -C model_and_code/ . \n",
    "\n",
    "from sagemaker.s3 import S3Uploader\n",
    "file_key = 'model.tar.gz'\n",
    "model_artifact = S3Uploader.upload(file_key,'s3://{}/{}/model'.format(bucket, prefix))\n",
    "print(model_artifact)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "17e2c63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.eu-west-1.amazonaws.com/pytorch-inference:1.11.0-gpu-py38\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "deploy_instance_type = 'ml.g4dn.xlarge'\n",
    "pytorch_inference_image_uri = retrieve('pytorch',\n",
    "                                       region,\n",
    "                                       version='1.11.0',\n",
    "                                       py_version='py38',\n",
    "                                       instance_type = deploy_instance_type,\n",
    "                                       accelerator_type=None,\n",
    "                                       image_scope='inference')\n",
    "\n",
    "# pytorch_inference_image_uri = \"763104351884.dkr.ecr.eu-west-1.amazonaws.com/pytorch-inference:1.11.0-gpu-py38-cu113-ubuntu20.04-sagemaker\"\n",
    "print(pytorch_inference_image_uri)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "43df6a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.eu-west-1.amazonaws.com/pytorch-inference:1.11.0-gpu-py38\n",
      "sagemaker-monai-brain-tumor-1654808393\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "container = pytorch_inference_image_uri\n",
    "model_name = 'sagemaker-monai-brain-tumor-{0}'.format(str(int(time.time())))\n",
    "print(container)\n",
    "print(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "87870620",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': container,\n",
    "        'ModelDataUrl': model_artifact,\n",
    "        'Environment': {\n",
    "            'TS_MAX_REQUEST_SIZE': '200000000', #default max request size is 6 Mb for torchserve, need to update it to support the 70 mb input payload\n",
    "            'TS_MAX_RESPONSE_SIZE': '200000000',\n",
    "            'TS_DEFAULT_RESPONSE_TIMEOUT': '1000'\n",
    "        }\n",
    "    },    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "aa695296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-monai-brain-tumor-1654808393\n",
      "Created EndpointConfig: arn:aws:sagemaker:eu-west-1:617011600974:endpoint-config/monaiendpointconfig-2022-06-09-20-59-58\n"
     ]
    }
   ],
   "source": [
    "print(model_name)\n",
    "endpoint_config_name = f\"monaiEndpointConfig-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.g4dn.xlarge\",\n",
    "            \"InitialInstanceCount\": 1\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(f\"Created EndpointConfig: {create_endpoint_config_response['EndpointConfigArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5a6ff5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_prefix = \"monai-async-inference\"\n",
    "resource_name = \"Monai-AsyncInferenceDemo-SNS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "02c5aba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sns:eu-west-1:617011600974:Monai-Async-Demo-ErrorTopic\n"
     ]
    }
   ],
   "source": [
    "response = sns_client.create_topic(Name=\"Monai-Async-Demo-ErrorTopic\")\n",
    "error_topic= response['TopicArn']\n",
    "print(error_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d9da0af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sns:eu-west-1:617011600974:Monai-Async-Demo-SuccessTopic\n"
     ]
    }
   ],
   "source": [
    "response = sns_client.create_topic(Name=\"Monai-Async-Demo-SuccessTopic\")\n",
    "success_topic = response['TopicArn']\n",
    "print(success_topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "02453a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'TopicArn': 'arn:aws:sns:eu-west-1:617011600974:AmazonRekognitionECGAlert'}, {'TopicArn': 'arn:aws:sns:eu-west-1:617011600974:BCDataBrewAtena'}, {'TopicArn': 'arn:aws:sns:eu-west-1:617011600974:Monai-Async-Demo-ErrorTopic'}, {'TopicArn': 'arn:aws:sns:eu-west-1:617011600974:Monai-Async-Demo-SuccessTopic'}]\n"
     ]
    }
   ],
   "source": [
    "response = sns_client.list_topics()\n",
    "topics = response[\"Topics\"]\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db94358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: Replace with your email id\n",
    "\n",
    "# email_id = 'your-email@domain-name.com'\n",
    "# email_sub_1 = sns_client.subscribe(\n",
    "#     TopicArn=success_topic,\n",
    "#     Protocol='email',\n",
    "#     Endpoint=email_id)\n",
    "\n",
    "# email_sub_2 = sns_client.subscribe(\n",
    "#     TopicArn=error_topic,\n",
    "#     Protocol='email',\n",
    "#     Endpoint=email_id)\n",
    "\n",
    "#Note: You will need to confirm by clicking on the email you recieve to complete the subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "288e3463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-monai-brain-tumor-1654808393\n",
      "Created EndpointConfig: arn:aws:sagemaker:eu-west-1:617011600974:endpoint-config/monai-asyncendpointconfig-2022-06-09-21-00-52\n"
     ]
    }
   ],
   "source": [
    "print(model_name)\n",
    "endpoint_config_name = f\"Monai-AsyncEndpointConfig-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.g4dn.xlarge\",\n",
    "            \"InitialInstanceCount\": 1\n",
    "        }\n",
    "    ],\n",
    "    AsyncInferenceConfig={\n",
    "        \"OutputConfig\": {\n",
    "            \"S3OutputPath\": f\"s3://{bucket}/{bucket_prefix}/output\",\n",
    "            #  Optionally specify Amazon SNS topics\n",
    "            \"NotificationConfig\": {\n",
    "              \"SuccessTopic\": success_topic,\n",
    "              \"ErrorTopic\": error_topic,\n",
    "            }\n",
    "        },\n",
    "        \"ClientConfig\": {\n",
    "            \"MaxConcurrentInvocationsPerInstance\": 2\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"Created EndpointConfig: {create_endpoint_config_response['EndpointConfigArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0a0268bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint: arn:aws:sagemaker:eu-west-1:617011600974:endpoint/monai-async-sm-2022-06-09-21-00-56\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = f\"monai-async-sm-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "create_endpoint_response = sm_client.create_endpoint(EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name)\n",
    "print(f\"Creating Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c31ae9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for endpoint to create...\n",
      "Endpoint Status: InService\n"
     ]
    }
   ],
   "source": [
    "waiter = boto3.client('sagemaker').get_waiter('endpoint_in_service')\n",
    "print(\"Waiting for endpoint to create...\")\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "print(f\"Endpoint Status: {resp['EndpointStatus']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "645c9356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OutputLocation: s3://sagemaker-eu-west-1-617011600974/monai-async-inference/output/9420a136-3d68-4794-84be-5be4b16542c4.out\n"
     ]
    }
   ],
   "source": [
    "s3_uri = \"s3://bcinspectio/old/brain_tumor/Task01_BrainTumor/imagesTr/BRATS_001.nii.gz\"\n",
    "response = sm_runtime.invoke_endpoint_async(\n",
    "    EndpointName=endpoint_name, \n",
    "    InputLocation=s3_uri)\n",
    "output_location = response['OutputLocation']\n",
    "print(f\"OutputLocation: {output_location}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8caea575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def get_output(output_location):\n",
    "    output_url = urllib.parse.urlparse(output_location)\n",
    "    bucket = output_url.netloc\n",
    "    key = output_url.path[1:]\n",
    "    while True:\n",
    "        try:\n",
    "            return sm_session.read_s3_file(bucket=output_url.netloc, key_prefix=output_url.path[1:])\n",
    "        except ClientError as e:\n",
    "            if e.response['Error']['Code'] == 'NoSuchKey':\n",
    "                print(\"waiting for output...\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02fd2abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n",
      "waiting for output...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchKey\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_94734/2290694397.py\u001b[0m in \u001b[0;36mget_output\u001b[0;34m(output_location)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msm_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_s3_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClientError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MonaiBrainTumorOnSagemaker/venv/lib64/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mread_s3_file\u001b[0;34m(self, bucket, key_prefix)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;31m# Explicitly passing a None kms_key to boto3 throws a validation error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0ms3_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MonaiBrainTumorOnSagemaker/venv/lib64/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MonaiBrainTumorOnSagemaker/venv/lib64/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchKey\u001b[0m: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_94734/1069557561.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Output size in bytes: {((sys.getsizeof(output)))}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_94734/2290694397.py\u001b[0m in \u001b[0;36mget_output\u001b[0;34m(output_location)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NoSuchKey'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"waiting for output...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "output = get_output(output_location)\n",
    "print(f\"Output size in bytes: {((sys.getsizeof(output)))}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m75"
  },
  "instance_type": "ml.g4dn.2xlarge",
  "interpreter": {
   "hash": "9064e900e2a765fc99668de545d3e0521ebc66fcd740a788637e4252a4141f7a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
