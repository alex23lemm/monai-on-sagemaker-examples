{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8712c732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu-west-1\n",
      "arn:aws:iam::617011600974:role/service-role/AmazonSageMaker-ExecutionRole-20210316T155032\n",
      "sagemaker-eu-west-1-617011600974\n",
      "monai-async-inference-brain-tumor\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import torch\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "import boto3\n",
    "import datetime\n",
    "import time\n",
    "from time import strftime,gmtime\n",
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import sys\n",
    "import io\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "sm_session = sagemaker.session.Session()\n",
    "sm_client = boto_session.client(\"sagemaker\")\n",
    "sm_runtime = boto_session.client(\"sagemaker-runtime\")\n",
    "sns_client = boto3.client('sns')\n",
    "region = boto_session.region_name\n",
    "bucket = sm_session.default_bucket()\n",
    "prefix = 'monai-async-inference-brain-tumor'\n",
    "role = \"arn:aws:iam::617011600974:role/service-role/AmazonSageMaker-ExecutionRole-20210316T155032\"\n",
    "\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)\n",
    "print(prefix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62d55c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘model_and_code’: File exists\n",
      "mkdir: cannot create directory ‘model_and_code/code’: File exists\n",
      "./\n",
      "./model.pth\n",
      "./code/\n",
      "./code/inference.py\n",
      "./code/requirements.txt\n",
      "s3://sagemaker-eu-west-1-617011600974/monai-async-inference-brain-tumor/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"MONAI-DEMO-MultiModelModel\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "#model_url = \"s3://sagemaker-eu-west-1-617011600974/monai-on-sagemaker-docker-2022-06-03-08-24-03-985/output/model.tar.gz\"\n",
    "\n",
    "!mkdir model_and_code\n",
    "!cp ./model/model.pth model_and_code/\n",
    "#torch.save(model, 'model_and_code/model.pth')\n",
    "!mkdir model_and_code/code\n",
    "!cp ./source/* model_and_code/code\n",
    "!tar cvzf model.tar.gz -C model_and_code/ . \n",
    "\n",
    "from sagemaker.s3 import S3Uploader\n",
    "file_key = 'model.tar.gz'\n",
    "model_artifact = S3Uploader.upload(file_key,'s3://{}/{}/model'.format(bucket, prefix))\n",
    "print(model_artifact)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17e2c63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.eu-west-1.amazonaws.com/pytorch-inference:1.11.0-gpu-py38\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "deploy_instance_type = 'ml.g4dn.xlarge'\n",
    "pytorch_inference_image_uri = retrieve('pytorch',\n",
    "                                       region,\n",
    "                                       version='1.11.0',\n",
    "                                       py_version='py38',\n",
    "                                       instance_type = deploy_instance_type,\n",
    "                                       accelerator_type=None,\n",
    "                                       image_scope='inference')\n",
    "print(pytorch_inference_image_uri)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43df6a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.eu-west-1.amazonaws.com/pytorch-inference:1.11.0-gpu-py38\n",
      "sagemaker-monai-brain-tumor-1654754484\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "container = pytorch_inference_image_uri\n",
    "model_name = 'sagemaker-monai-brain-tumor-{0}'.format(str(int(time.time())))\n",
    "print(container)\n",
    "print(model_name)\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': container,\n",
    "        'ModelDataUrl': model_artifact,\n",
    "        'Environment': {\n",
    "            'TS_MAX_REQUEST_SIZE': '100000000', #default max request size is 6 Mb for torchserve, need to update it to support the 70 mb input payload\n",
    "            'TS_MAX_RESPONSE_SIZE': '100000000',\n",
    "            'TS_DEFAULT_RESPONSE_TIMEOUT': '1000'\n",
    "        }\n",
    "    },    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa695296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-monai-brain-tumor-1654754484\n",
      "Created EndpointConfig: arn:aws:sagemaker:eu-west-1:617011600974:endpoint-config/monaiendpointconfig-2022-06-09-06-02-00\n"
     ]
    }
   ],
   "source": [
    "print(model_name)\n",
    "endpoint_config_name = f\"monaiEndpointConfig-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.g4dn.xlarge\",\n",
    "            \"InitialInstanceCount\": 1\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(f\"Created EndpointConfig: {create_endpoint_config_response['EndpointConfigArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cc13918",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"sm-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "846042d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for endpoint to create...\n",
      "Endpoint Status: InService\n"
     ]
    }
   ],
   "source": [
    "waiter = boto3.client('sagemaker').get_waiter('endpoint_in_service')\n",
    "print(\"Waiting for endpoint to create...\")\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "print(f\"Endpoint Status: {resp['EndpointStatus']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "decd9ce0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from primary with message \"'collections.OrderedDict' object has no attribute 'to'\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 126, in transform\n    result = self._transform_fn(self._model, input_data, content_type, accept)\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 216, in _default_transform_fn\n    prediction = self._predict_fn(data, model)\n  File \"/opt/ml/model/code/inference.py\", line 78, in predict_fn\n    model = model.to(device)\nAttributeError: 'collections.OrderedDict' object has no attribute 'to'\n\". See https://eu-west-1.console.aws.amazon.com/cloudwatch/home?region=eu-west-1#logEventViewer:group=/aws/sagemaker/Endpoints/sm-2022-06-09-06-02-16 in account 617011600974 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_63306/356279479.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Test Data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msm_runtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sagemaker-runtime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm_runtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEndpointName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/MonaiBrainTumorOnSagemaker/venv/lib64/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 )\n\u001b[1;32m    507\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MonaiBrainTumorOnSagemaker/venv/lib64/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from primary with message \"'collections.OrderedDict' object has no attribute 'to'\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 126, in transform\n    result = self._transform_fn(self._model, input_data, content_type, accept)\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 216, in _default_transform_fn\n    prediction = self._predict_fn(data, model)\n  File \"/opt/ml/model/code/inference.py\", line 78, in predict_fn\n    model = model.to(device)\nAttributeError: 'collections.OrderedDict' object has no attribute 'to'\n\". See https://eu-west-1.console.aws.amazon.com/cloudwatch/home?region=eu-west-1#logEventViewer:group=/aws/sagemaker/Endpoints/sm-2022-06-09-06-02-16 in account 617011600974 for more information."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ep= endpoint_name\n",
    "feed_data = \"Test Data\"\n",
    "sm_runtime = boto3.Session().client('sagemaker-runtime')\n",
    "r = sm_runtime.invoke_endpoint(EndpointName=ep, Body=feed_data)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m75"
  },
  "instance_type": "ml.g4dn.2xlarge",
  "interpreter": {
   "hash": "9064e900e2a765fc99668de545d3e0521ebc66fcd740a788637e4252a4141f7a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
